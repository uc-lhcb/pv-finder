{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we grab matplotlib, and set the old \"classic\" style for some reason only Rui knows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('classic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the local imports. Make sure you import the correct model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.models import AltCNN4Layer_D35_sp as Model\n",
    "from model.collectdata import collect_data, collect_truth\n",
    "from model.training import select_gpu\n",
    "from model.plots import plot_ruiplot\n",
    "from model.efficiency import pv_locations, efficiency\n",
    "from model.core import modernize_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a GPU here. Same numbering as the NVidia-SMI tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = select_gpu(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a file to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = collect_data('data/Oct03_20K_val.h5',\n",
    "                          batch_size=1,\n",
    "                          slice=slice(100),\n",
    "                          masking=True,\n",
    "                          device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "XY_file = 'data/Oct03_20K_val.h5'\n",
    "\n",
    "with h5py.File(XY_file, mode='r') as XY:\n",
    "    xmax = np.asarray(XY['Xmax'])\n",
    "    ymax = np.asarray(XY['Ymax'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: to get the real PV locations, use `collect_truth('file.h5', pvs=True)` to collect PVs (or SVs with `pvs=False`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just see how many NaNs we have in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*np.sum(np.isnan(validation.dataset.tensors[1].cpu().numpy()), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV = collect_truth('data/Oct03_20K_val.h5', pvs=True)\n",
    "print('PV.n.shape =    ',  PV.n.shape)\n",
    "print('PV.n[0].shape = ', *PV.n[0].shape)\n",
    "print('PV.x[0] =       ', *PV.x[0])\n",
    "print('PV.y[0] =       ', *PV.y[0])\n",
    "print('PV.z[0] =       ', *PV.z[0])\n",
    "print('PV.n[0] =       ', *PV.n[0])\n",
    "print('PV.cat[0] =     ', *PV.cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, awkward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "z_list = []\n",
    "n_list = []\n",
    "c_list = []\n",
    "\n",
    "p = 'p'\n",
    "\n",
    "with h5py.File('temp.h5', mode='r') as XY:\n",
    "    afile = awkward.persist.hdf5(XY)\n",
    "    x_list.append(afile[f\"{p}v_loc_x\"])\n",
    "    y_list.append(afile[f\"{p}v_loc_y\"])\n",
    "    z_list.append(afile[f\"{p}v_loc\"])\n",
    "    n_list.append(afile[f\"{p}v_ntracks\"])\n",
    "    c_list.append(afile[f\"{p}v_cat\"])\n",
    "\n",
    "print(x_list[0].JaggedArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import awkward0 as awkward\n",
    "except ModuleNotFoundError:\n",
    "    import awkward\n",
    "import h5py, numpy as np\n",
    "\n",
    "simple = awkward.JaggedArray.fromcounts([2,3], [1.,2,3,4,5])\n",
    "\n",
    "with h5py.File('example.h5', mode='w') as f:\n",
    "    af = awkward.persist.hdf5(f)\n",
    "    af['example'] = simple\n",
    "    \n",
    "with h5py.File('example.h5', mode='r') as f:\n",
    "    af = awkward.persist.hdf5(f)\n",
    "    example = af['example']\n",
    "    \n",
    "print(example.JaggedArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('temp.h5', mode='r') as XY:\n",
    "    schema = XY['pv_loc_x']['schema.json'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.string_(schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV.n.flatten().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV.cat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SV = collect_truth('data/Oct03_20K_val.h5', pvs=False)\n",
    "print('SV.n.shape =    ', SV.n.shape)\n",
    "print('SV.n[0].shape = ', *SV.n[0].shape)\n",
    "print('SV.x[0] =       ', *SV.x[0])\n",
    "print('SV.y[0] =       ', *SV.y[0])\n",
    "print('SV.z[0] =       ', *SV.z[0])\n",
    "print('SV.n[0] =       ', *SV.n[0])\n",
    "print('SV.cat[0] =     ', *SV.cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a model to load. Make sure it matches the model you imported above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Mike note:\n",
    ">\n",
    "> If you use an old-style model, comment out the `d = modernize(d, 3)` line - that converts the old model key names to the new format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load(\n",
    "    '/share/lazy/schreihf/PvFinder/models/'\n",
    "    '07Jan19_AltCNN4Layer_D35_sp_300epochs'\n",
    "    '_240K_lr_3em5_bs256_Alt_Loss_A_5p5/'\n",
    "    '07Jan19_AltCNN4Layer_D35_sp_300epochs'\n",
    "    '_240K_lr_3em5_bs256_Alt_Loss_A_5p5_199.pyt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del state['fc1.weight'], state['fc1.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = modernize_state(model, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.load_state_dict(state)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab the outputs and labels as normal numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    outputs = model(validation.dataset.tensors[0]).cpu().numpy()\n",
    "    labels = validation.dataset.tensors[1].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle = cycler(color=['black', '#444444', '#888888'])\n",
    "hatch=['/', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styledict = {\n",
    "    'font.size':18,\n",
    "    'font.weight':'bold',\n",
    "    'axes.prop_cycle': cycle,\n",
    "}\n",
    "fontdict = {\n",
    "    'size':18,\n",
    "    'weight':'bold',\n",
    "}\n",
    "rui_styles = {\n",
    "    'kernel': dict(facecolor='none', hatch=''),\n",
    "    'target': dict(facecolor='none', hatch='/'),\n",
    "    'predicted': dict(facecolor='none', hatch='\\\\'),\n",
    "    'masked': dict(facecolor='none', hatch='*'),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's Rui's plotting code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = validation.dataset.tensors[0].cpu().numpy().squeeze()\n",
    "zvals = np.linspace(-100, 300, 4000, endpoint=False) + 0.05\n",
    "finalmsg = ''\n",
    "internal_count = 0\n",
    "output_filename = '07Jan19_AltCNN4Layer_D35_sp_{number:02}.pdf'\n",
    "#  None # Or set: '120000_3layer_{number:02}.pdf'\n",
    "\n",
    "for event in range(2):\n",
    "    input = inputs[event]\n",
    "    label = labels[event]\n",
    "    output = outputs[event]\n",
    "    \n",
    "    # Consistent parameters for the calls below\n",
    "    parameters = {\n",
    "        \"threshold\": 1e-2,\n",
    "        \"integral_threshold\": .2,\n",
    "        \"min_width\": 3\n",
    "    }\n",
    "    \n",
    "    # Compute the \"actual\" efficenies and things\n",
    "    ftruth = pv_locations(label, **parameters)\n",
    "    fcomputed = pv_locations(output, **parameters)\n",
    "    results = efficiency(label, output, difference=5.0, **parameters)\n",
    "    \n",
    "    # Add a line to the final results string (print at end)\n",
    "    finalmsg += f\"Event {event}: {results}\\n\"\n",
    "    \n",
    "    # Make sure bin numbers are integers\n",
    "    truth = np.around(ftruth).astype(np.int32)\n",
    "    computed = np.around(fcomputed).astype(np.int32)\n",
    "    \n",
    "    # Join arrays and remove any points closer than 5 bins\n",
    "    # We plot over these \"points of interest\"\n",
    "    poi = np.sort(np.concatenate([truth, computed]))\n",
    "    poi = poi[np.concatenate([[True], np.fabs(np.diff(poi)) > 5])]\n",
    "    \n",
    "    print(f\"\\nEvent {event}:\", results)\n",
    "    \n",
    "    for index, i in enumerate(poi):\n",
    "        # Convert to location in z\n",
    "        center = (i / 10) - 100\n",
    "        \n",
    "        # Collect items less than 5 apart as \"true\"\n",
    "        b_truth = np.fabs(ftruth - i) <= 5\n",
    "        b_comp = np.fabs(fcomputed - i) <= 5\n",
    "        in_truth = np.any(b_truth)\n",
    "        in_comp = np.any(b_comp)\n",
    "        \n",
    "        if in_truth and in_comp:\n",
    "            msg = 'PV found'\n",
    "        elif in_truth:\n",
    "            msg = 'PV not found'\n",
    "        elif np.any(np.isnan(label[i-3:i+3])):\n",
    "            msg = 'Masked'\n",
    "        else:\n",
    "            msg = 'False positive'\n",
    "            \n",
    "        with plt.style.context(styledict):\n",
    "        \n",
    "            fig, axs = plt.subplots(2, figsize=(12,10), sharex=True,\n",
    "                                    gridspec_kw={'height_ratios':[2,1],\n",
    "                                                'hspace':0.1})\n",
    "        \n",
    "            # ax1 is the axis that is tied to left (density)\n",
    "            # ax2 is the axis that is tied to the right (probability)\n",
    "            ax1, ax2 = plot_ruiplot(zvals, i, input, label, output, ax=axs[0], styles=rui_styles)\n",
    "            ax1.set_title(f\"Event {event} @ {center:.1f} mm: {msg}\",\n",
    "                          fontdict=fontdict)\n",
    "\n",
    "\n",
    "            msg = \"\"\n",
    "            \n",
    "            truth_centroid = (ftruth[b_truth] / 10) - 100\n",
    "            for value in truth_centroid:\n",
    "                msg += f\"True: {value:.3f} mm\\n\"\n",
    "                \n",
    "            comp_centroid = (fcomputed[b_comp] / 10) - 100\n",
    "            for value in comp_centroid:\n",
    "                msg += f\"Pred: {value:.3f} mm\\n\"\n",
    "                \n",
    "            if len(truth_centroid) == 1 and len(comp_centroid) == 1:\n",
    "                diff = (comp_centroid[0] - truth_centroid[0]) * 1_000\n",
    "                msg += f\"∆: {diff:.0f} µm\\n\"\n",
    "            \n",
    "            ax1.text(.02, .8, msg,\n",
    "                     transform=ax1.transAxes,\n",
    "                     verticalalignment='top')\n",
    "            \n",
    "            print(f\"\\nEvent {event}.{index}:\")\n",
    "            \n",
    "            # Plot and print PVs\n",
    "            ax2.scatter(PV.z[event], np.ones_like(PV.z[event])*.4, s=50, color='C0')\n",
    "            for x,y,z,n,cat in zip(PV.x[event], PV.y[event], PV.z[event], PV.n[event], PV.cat[event]):\n",
    "                # Only print out if z in plotting range\n",
    "                if center - 2.5 < z < center + 2.5:\n",
    "                    print()\n",
    "                    print(f'PV: {n} tracks (type {cat})')\n",
    "                    print(f'  x: {x*1000:5.0f} μm')\n",
    "                    print(f'  y: {y*1000:5.0f} μm')\n",
    "                    print(f'  z: {z:8.3f} mm')\n",
    "                    \n",
    "\n",
    "            # Plot and print SVs\n",
    "            ax2.scatter(SV.z[event], np.ones_like(SV.z[event])*.6, s=50, color='C1')\n",
    "            for x,y,z,n,cat in zip(SV.x[event], SV.y[event], SV.z[event], SV.n[event], SV.cat[event]):\n",
    "                # Only print out if z in plotting range\n",
    "                if center - 2.5 < z < center + 2.5:\n",
    "                    print()\n",
    "                    print(f'SV: {n} tracks (type {cat})')\n",
    "                    print(f'  x: {x*1000:5.0f} μm')\n",
    "                    print(f'  y: {y*1000:5.0f} μm')\n",
    "                    print(f'  z: {z:8.3f} mm')\n",
    "            \n",
    "            ax = axs[1]\n",
    "            ax.plot((np.arange(4000) / 10) - 100, xmax[event]*1000000, label=\"x\")\n",
    "            ax.plot((np.arange(4000) / 10) - 100, ymax[event]*1000000, label=\"y\")\n",
    "            ax.set_xlim(ax1.get_xlim())\n",
    "            ax.set_ylim(-150,150)\n",
    "            ax.grid(axis='y')\n",
    "            ax.set_ylabel('xy maximum [μm]')\n",
    "            ax.legend(loc='best')\n",
    "            \n",
    "            ax.set_xlabel(ax1.get_xlabel())\n",
    "            ax1.set_xlabel(\"\")\n",
    "            \n",
    "            if output_filename:\n",
    "                print()\n",
    "                print(output_filename.format(number=internal_count))\n",
    "            \n",
    "            # Save and show\n",
    "            if output_filename:        \n",
    "                plt.savefig(output_filename.format(number=internal_count), transparent=True)\n",
    "            plt.show()\n",
    "            \n",
    "            internal_count += 1\n",
    "            \n",
    "print(finalmsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
