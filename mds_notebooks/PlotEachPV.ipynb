{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun  1 17:26:41 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN V             Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 28%   41C    P8    24W / 250W |   9057MiB / 12066MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:83:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    28W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN V             Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 31%   45C    P8    28W / 250W |   9749MiB / 12066MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     22836      C   ...a/conda/envs/goofit-june2020/bin/python  9045MiB |\n",
      "|    2     33919      C   ...a/conda/envs/goofit-june2020/bin/python  9737MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we grab matplotlib, and set the old \"classic\" style for some reason only Rui knows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('classic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the local imports. Make sure you import the correct model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.models import AltCNN4Layer_D35_sp as Model\n",
    "from model.collectdata import collect_data, collect_truth\n",
    "from model.training import select_gpu\n",
    "from model.plots import plot_ruiplot\n",
    "from model.efficiency import pv_locations, efficiency\n",
    "from model.core import modernize_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a GPU here. Same numbering as the NVidia-SMI tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 available GPUs (initially using device 0):\n",
      "  0 TITAN V\n"
     ]
    }
   ],
   "source": [
    "device = select_gpu(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a file to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded data/Oct03_20K_val.h5 in 3.666 s\n",
      "Constructing 100 event dataset took 5.047 s\n"
     ]
    }
   ],
   "source": [
    "validation = collect_data('data/Oct03_20K_val.h5',\n",
    "                          batch_size=1,\n",
    "                          slice=slice(100),\n",
    "                          masking=True,\n",
    "                          device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "XY_file = 'data/Oct03_20K_val.h5'\n",
    "\n",
    "with h5py.File(XY_file, mode='r') as XY:\n",
    "    xmax = np.asarray(XY['Xmax'])\n",
    "    ymax = np.asarray(XY['Ymax'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: to get the real PV locations, use `collect_truth('file.h5', pvs=True)` to collect PVs (or SVs with `pvs=False`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just see how many NaNs we have in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 6 0 12 18 28 29 12 23 16 17 79 20 18 37 0 12 43 11 21 38 0 35 23 22 22 23 33 27 16 0 23 17 56 17 38 16 45 12 12 12 22 22 11 12 44 17 45 6 17 39 28 33 17 39 62 53 29 6 6 5 46 53 34 22 29 17 63 17 12 18 22 50 18 28 12 41 29 22 34 35 17 42 11 57 27 16 22 23 33 23 33 16 45 30 0 6 16 28 17\n"
     ]
    }
   ],
   "source": [
    "print(*np.sum(np.isnan(validation.dataset.tensors[1].cpu().numpy()), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data/Oct03_20K_val.h5 in 0.03177 s\n",
      "PV.n.shape =     (20000,)\n",
      "PV.n[0].shape =  7\n",
      "PV.x[0] =        0.0067699254 -0.05386329 0.0018882935 -0.035012268 -0.010384369 0.045956675 -0.073287025\n",
      "PV.y[0] =        0.00076032506 -0.001020242 -0.03236149 0.043514606 -0.08862019 -0.06502226 -0.0052683405\n",
      "PV.z[0] =        163.4873 80.101074 1.0544614 -36.59213 115.55979 48.95428 126.700806\n",
      "PV.n[0] =        34 10 4 23 4 29 4\n",
      "PV.cat[0] =      1 1 0 1 0 1 0\n"
     ]
    }
   ],
   "source": [
    "PV = collect_truth('data/Oct03_20K_val.h5', pvs=True)\n",
    "print('PV.n.shape =    ',  PV.n.shape)\n",
    "print('PV.n[0].shape = ', *PV.n[0].shape)\n",
    "print('PV.x[0] =       ', *PV.x[0])\n",
    "print('PV.y[0] =       ', *PV.y[0])\n",
    "print('PV.z[0] =       ', *PV.z[0])\n",
    "print('PV.n[0] =       ', *PV.n[0])\n",
    "print('PV.cat[0] =     ', *PV.cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "try:\n",
    "    import awkward0 as awkward\n",
    "except ModuleNotFoundError:\n",
    "    import awkward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "z_list = []\n",
    "n_list = []\n",
    "c_list = []\n",
    "\n",
    "p = 'p'\n",
    "\n",
    "with h5py.File('temp.h5', mode='r') as XY:\n",
    "    afile = awkward.persist.hdf5(XY)\n",
    "    x_list.append(afile[f\"{p}v_loc_x\"])\n",
    "    y_list.append(afile[f\"{p}v_loc_y\"])\n",
    "    z_list.append(afile[f\"{p}v_loc\"])\n",
    "    n_list.append(afile[f\"{p}v_ntracks\"])\n",
    "    c_list.append(afile[f\"{p}v_cat\"])\n",
    "\n",
    "print(x_list[0].JaggedArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple = awkward.JaggedArray.fromcounts([2,3], [1.,2,3,4,5])\n",
    "\n",
    "with h5py.File('example.h5', mode='w') as f:\n",
    "    af = awkward.persist.hdf5(f)\n",
    "    af['example'] = simple\n",
    "    \n",
    "with h5py.File('example.h5', mode='r') as f:\n",
    "    af = awkward.persist.hdf5(f)\n",
    "    example = af['example']\n",
    "    \n",
    "print(example.JaggedArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('temp.h5', mode='r') as XY:\n",
    "    schema = XY['pv_loc_x']['schema.json'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.string_(schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV.n.flatten().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV.cat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SV = collect_truth('data/Oct03_20K_val.h5', pvs=False)\n",
    "print('SV.n.shape =    ', SV.n.shape)\n",
    "print('SV.n[0].shape = ', *SV.n[0].shape)\n",
    "print('SV.x[0] =       ', *SV.x[0])\n",
    "print('SV.y[0] =       ', *SV.y[0])\n",
    "print('SV.z[0] =       ', *SV.z[0])\n",
    "print('SV.n[0] =       ', *SV.n[0])\n",
    "print('SV.cat[0] =     ', *SV.cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a model to load. Make sure it matches the model you imported above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Mike note:\n",
    ">\n",
    "> If you use an old-style model, comment out the `d = modernize(d, 3)` line - that converts the old model key names to the new format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load(\n",
    "    '/share/lazy/schreihf/PvFinder/models/'\n",
    "    '07Jan19_AltCNN4Layer_D35_sp_300epochs'\n",
    "    '_240K_lr_3em5_bs256_Alt_Loss_A_5p5/'\n",
    "    '07Jan19_AltCNN4Layer_D35_sp_300epochs'\n",
    "    '_240K_lr_3em5_bs256_Alt_Loss_A_5p5_199.pyt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del state['fc1.weight'], state['fc1.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = modernize_state(model, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.load_state_dict(state)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab the outputs and labels as normal numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    outputs = model(validation.dataset.tensors[0]).cpu().numpy()\n",
    "    labels = validation.dataset.tensors[1].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontdict = {\n",
    "    'font.size':18,\n",
    "    'font.weight':'bold'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's Rui's plotting code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = validation.dataset.tensors[0].cpu().numpy().squeeze()\n",
    "zvals = np.linspace(-100, 300, 4000, endpoint=False) + 0.05\n",
    "finalmsg = ''\n",
    "internal_count = 0\n",
    "output_filename = '07Jan19_AltCNN4Layer_D35_sp_{number:02}.pdf'\n",
    "#  None # Or set: '120000_3layer_{number:02}.pdf'\n",
    "\n",
    "for event in range(2):\n",
    "    input = inputs[event]\n",
    "    label = labels[event]\n",
    "    output = outputs[event]\n",
    "    \n",
    "    # Consistent parameters for the calls below\n",
    "    parameters = {\n",
    "        \"threshold\": 1e-2,\n",
    "        \"integral_threshold\": .2,\n",
    "        \"min_width\": 3\n",
    "    }\n",
    "    \n",
    "    # Compute the \"actual\" efficenies and things\n",
    "    ftruth = pv_locations(label, **parameters)\n",
    "    fcomputed = pv_locations(output, **parameters)\n",
    "    results = efficiency(label, output, difference=5.0, **parameters)\n",
    "    \n",
    "    # Add a line to the final results string (print at end)\n",
    "    finalmsg += f\"Event {event}: {results}\\n\"\n",
    "    \n",
    "    # Make sure bin numbers are integers\n",
    "    truth = np.around(ftruth).astype(np.int32)\n",
    "    computed = np.around(fcomputed).astype(np.int32)\n",
    "    \n",
    "    # Join arrays and remove any points closer than 5 bins\n",
    "    # We plot over these \"points of interest\"\n",
    "    poi = np.sort(np.concatenate([truth, computed]))\n",
    "    poi = poi[np.concatenate([[True], np.fabs(np.diff(poi)) > 5])]\n",
    "    \n",
    "    print(f\"\\nEvent {event}:\", results)\n",
    "    \n",
    "    for index, i in enumerate(poi):\n",
    "        # Convert to location in z\n",
    "        center = (i / 10) - 100\n",
    "        \n",
    "        # Collect items less than 5 apart as \"true\"\n",
    "        b_truth = np.fabs(ftruth - i) <= 5\n",
    "        b_comp = np.fabs(fcomputed - i) <= 5\n",
    "        in_truth = np.any(b_truth)\n",
    "        in_comp = np.any(b_comp)\n",
    "        \n",
    "        if in_truth and in_comp:\n",
    "            msg = 'PV found'\n",
    "        elif in_truth:\n",
    "            msg = 'PV not found'\n",
    "        elif np.any(np.isnan(label[i-3:i+3])):\n",
    "            msg = 'Masked'\n",
    "        else:\n",
    "            msg = 'False positive'\n",
    "            \n",
    "        with plt.style.context(fontdict):\n",
    "        \n",
    "            fig, axs = plt.subplots(2, figsize=(12,10), sharex=True,\n",
    "                                    gridspec_kw={'height_ratios':[2,1],\n",
    "                                                'hspace':0.1})\n",
    "        \n",
    "            # ax1 is the axis that is tied to left (density)\n",
    "            # ax2 is the axis that is tied to the right (probability)\n",
    "            ax1, ax2 = plot_ruiplot(zvals, i, input, label, output, ax=axs[0])\n",
    "            ax1.set_title(f\"Event {event} @ {center:.1f} mm: {msg}\",\n",
    "                          fontdict=fontdict)\n",
    "\n",
    "\n",
    "            msg = \"\"\n",
    "            \n",
    "            truth_centroid = (ftruth[b_truth] / 10) - 100\n",
    "            for value in truth_centroid:\n",
    "                msg += f\"True: {value:.3f} mm\\n\"\n",
    "                \n",
    "            comp_centroid = (fcomputed[b_comp] / 10) - 100\n",
    "            for value in comp_centroid:\n",
    "                msg += f\"Pred: {value:.3f} mm\\n\"\n",
    "                \n",
    "            if len(truth_centroid) == 1 and len(comp_centroid) == 1:\n",
    "                diff = (comp_centroid[0] - truth_centroid[0]) * 1_000\n",
    "                msg += f\"∆: {diff:.0f} µm\\n\"\n",
    "            \n",
    "            ax1.text(.02, .8, msg,\n",
    "                     transform=ax1.transAxes,\n",
    "                     verticalalignment='top')\n",
    "            \n",
    "            print(f\"\\nEvent {event}.{index}:\")\n",
    "            \n",
    "            # Plot and print PVs\n",
    "            ax2.scatter(PV.z[event], np.ones_like(PV.z[event])*.4, s=50, color='C0')\n",
    "            for x,y,z,n,cat in zip(PV.x[event], PV.y[event], PV.z[event], PV.n[event], PV.cat[event]):\n",
    "                # Only print out if z in plotting range\n",
    "                if center - 2.5 < z < center + 2.5:\n",
    "                    print()\n",
    "                    print(f'PV: {n} tracks (type {cat})')\n",
    "                    print(f'  x: {x*1000:5.0f} μm')\n",
    "                    print(f'  y: {y*1000:5.0f} μm')\n",
    "                    print(f'  z: {z:8.3f} mm')\n",
    "                    \n",
    "\n",
    "            # Plot and print SVs\n",
    "            ax2.scatter(SV.z[event], np.ones_like(SV.z[event])*.6, s=50, color='C1')\n",
    "            for x,y,z,n,cat in zip(SV.x[event], SV.y[event], SV.z[event], SV.n[event], SV.cat[event]):\n",
    "                # Only print out if z in plotting range\n",
    "                if center - 2.5 < z < center + 2.5:\n",
    "                    print()\n",
    "                    print(f'SV: {n} tracks (type {cat})')\n",
    "                    print(f'  x: {x*1000:5.0f} μm')\n",
    "                    print(f'  y: {y*1000:5.0f} μm')\n",
    "                    print(f'  z: {z:8.3f} mm')\n",
    "            \n",
    "            ax = axs[1]\n",
    "            ax.plot((np.arange(4000) / 10) - 100, xmax[event]*1000000, label=\"x\")\n",
    "            ax.plot((np.arange(4000) / 10) - 100, ymax[event]*1000000, label=\"y\")\n",
    "            ax.set_xlim(ax1.get_xlim())\n",
    "            ax.set_ylim(-150,150)\n",
    "            ax.grid(axis='y')\n",
    "            ax.set_ylabel('xy maximum [μm]')\n",
    "            ax.legend(loc='best')\n",
    "            \n",
    "            ax.set_xlabel(ax1.get_xlabel())\n",
    "            ax1.set_xlabel(\"\")\n",
    "            \n",
    "            if output_filename:\n",
    "                print()\n",
    "                print(output_filename.format(number=internal_count))\n",
    "            \n",
    "            # Save and show\n",
    "            if output_filename:        \n",
    "                plt.savefig(output_filename.format(number=internal_count), transparent=True)\n",
    "            plt.show()\n",
    "            \n",
    "            internal_count += 1\n",
    "            \n",
    "print(finalmsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
