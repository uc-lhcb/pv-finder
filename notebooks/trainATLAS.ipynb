{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture _ \n",
    "# ^ this just silences warnings\n",
    "import torch\n",
    "import mlflow\n",
    "# import hiddenlayer as HL\n",
    "\n",
    "from model.collectdata_poca_KDE import collect_data_poca_ATLAS as collect_data_poca\n",
    "from model.alt_loss_A import Loss\n",
    "from model.training import trainNet, select_gpu\n",
    "from model.utilities import load_full_state, count_parameters, Params, save_to_mlflow\n",
    "\n",
    "from model.autoencoder_models import UNet\n",
    "from model.autoencoder_models import UNetPlusPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Params(\n",
    "    batch_size=64,\n",
    "    device = select_gpu(-1),\n",
    "    epochs=100,\n",
    "    lr=1e-2,\n",
    "    experiment_name='ATLAS UNet++',\n",
    "    asymmetry_parameter=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded /share/lazy/ekauffma/ATLAS_PVFinderData.h5 in 716.7 s\n",
      "Constructing 600 event dataset took 0.02162 s\n"
     ]
    }
   ],
   "source": [
    "events = 3000\n",
    "## This is used when training with the new KDE\n",
    "train_loader = collect_data_poca('/share/lazy/ekauffma/ATLAS_PVFinderData.h5',\n",
    "                            batch_size=args['batch_size'],\n",
    "                            device=args['device'], \n",
    "                            shuffle=True,\n",
    "                            load_A_and_B=True,\n",
    "                            load_xy=True,\n",
    "                            slice = slice(0,2400)\n",
    "                            #slice = slice(0,300)\n",
    "                           )\n",
    "\n",
    "val_loader = collect_data_poca('/share/lazy/ekauffma/ATLAS_PVFinderData.h5',\n",
    "                            batch_size=args['batch_size'],\n",
    "                            device=args['device'],\n",
    "                            shuffle=True,\n",
    "                            load_A_and_B=True,\n",
    "                            load_xy=True,\n",
    "                            slice = slice(2400,3000)\n",
    "                            #slice = slice(300,350)\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment 'ML'. Detailed error Yaml file '/share/lazy/pv-finder_model_repo/ML/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/home/ekauffma/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 256, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"/data/home/ekauffma/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 336, in _get_experiment\n",
      "    meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/data/home/ekauffma/.local/lib/python3.7/site-packages/mlflow/utils/file_utils.py\", line 175, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/share/lazy/pv-finder_model_repo/ML/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '14'. Detailed error Yaml file '/share/lazy/pv-finder_model_repo/14/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/home/ekauffma/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 256, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"/data/home/ekauffma/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 336, in _get_experiment\n",
      "    meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/data/home/ekauffma/.local/lib/python3.7/site-packages/mlflow/utils/file_utils.py\", line 175, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/share/lazy/pv-finder_model_repo/14/meta.yaml' does not exist.\n"
     ]
    }
   ],
   "source": [
    "mlflow.tracking.set_tracking_uri('file:/share/lazy/pv-finder_model_repo')\n",
    "mlflow.set_experiment(args['experiment_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetPlusPlus().to(args['device'])\n",
    "# for name, param in model.named_parameters():\n",
    "#     print (name, param.data)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], betas=(0.9, 0.999))\n",
    "loss = Loss(epsilon=1e-5,coefficient=args['asymmetry_parameter'])\n",
    "\n",
    "parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNetPlusPlus(\n",
      "  (rcbn1): ConvBNrelu(\n",
      "    (0): Conv1d(4, 64, kernel_size=(25,), stride=(1,), padding=(12,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (rcbn2): ConvBNrelu(\n",
      "    (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (rcbn3): ConvBNrelu(\n",
      "    (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (rcbn4): ConvBNrelu(\n",
      "    (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (rcbn5): ConvBNrelu(\n",
      "    (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (ui): ConvTranspose1d(64, 64, kernel_size=(2,), stride=(2,))\n",
      "  (i1): ConvBNrelu(\n",
      "    (0): Conv1d(128, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (i2): ConvBNrelu(\n",
      "    (0): Conv1d(128, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (i3): ConvBNrelu(\n",
      "    (0): Conv1d(128, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (i4): ConvBNrelu(\n",
      "    (0): Conv1d(192, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (i5): ConvBNrelu(\n",
      "    (0): Conv1d(192, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (i6): ConvBNrelu(\n",
      "    (0): Conv1d(256, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (up1): ConvTranspose1d(64, 64, kernel_size=(2,), stride=(2,))\n",
      "  (up_c1): ConvBNrelu(\n",
      "    (0): Conv1d(128, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (up2): ConvTranspose1d(64, 64, kernel_size=(2,), stride=(2,))\n",
      "  (up_c2): ConvBNrelu(\n",
      "    (0): Conv1d(192, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (up3): ConvTranspose1d(64, 64, kernel_size=(2,), stride=(2,))\n",
      "  (up_c3): ConvBNrelu(\n",
      "    (0): Conv1d(256, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (up4): ConvTranspose1d(64, 64, kernel_size=(2,), stride=(2,))\n",
      "  (up_c4): ConvBNrelu(\n",
      "    (0): Conv1d(320, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (out_intermediate): Conv1d(128, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (outc): Conv1d(64, 1, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (d): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: train = 38, val = 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33129fcd9ad74dfd8056d222d564ba58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epochs', layout=Layout(flex='2'), style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0542ec7e174eb698bde9dcaf8ba124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=38.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load_full_state(model, optimizer, '/share/lazy/pv-finder_model_repo/24/9a2b98a397eb404497b26ab5eaa091a5/artifacts/train.ipynb')\n",
    "\n",
    "run_name = 'second pass with ATLAS data - increased learning rate'\n",
    "\n",
    "# tune kernel based on gpu\n",
    "#torch.backends.cudnn.benchmark=True\n",
    "train_iter = enumerate(trainNet(model, optimizer, loss, train_loader, val_loader, args['epochs'], notebook=True))\n",
    "with mlflow.start_run(run_name = run_name) as run:\n",
    "    mlflow.log_artifact('train.ipynb')\n",
    "    for i, result in train_iter:\n",
    "        print(result.cost)\n",
    "        torch.save(model, 'run_stats.pyt')\n",
    "        mlflow.log_artifact('run_stats.pyt')\n",
    "\n",
    "        save_to_mlflow({\n",
    "            'Metric: Training loss':result.cost,\n",
    "            'Metric: Validation loss':result.val,\n",
    "            'Metric: Efficiency':result.eff_val.eff_rate,\n",
    "            'Metric: False positive rate':result.eff_val.fp_rate,\n",
    "            'Param: Parameters':parameters,\n",
    "            'Param: Events':events,\n",
    "            'Param: Asymmetry':args['asymmetry_parameter'],\n",
    "            'Param: Epochs':args['epochs'],\n",
    "        }, step=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
