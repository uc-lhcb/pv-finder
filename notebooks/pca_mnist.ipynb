{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25e4834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import einops\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f71dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have some images - batch of 16 that are 256x256x3\n",
    "images = torch.rand(16, 3, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3234c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model which processes the images \n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 16, 3)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 16, 3) \n",
    "        self.conv3 = torch.nn.Conv2d(16, 16, 3)\n",
    "        self.conv4 = torch.nn.Conv2d(16, 1, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "691e43d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Model()(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad59fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretend this is good model - lets get the good parameters from it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07983d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "tensors = []\n",
    "for name, tensor in model.state_dict().items():\n",
    "    if 'weight' in name:\n",
    "        tensors.append(tensor.view(-1, 9)) # 9 because we are using 3x3 kernels \n",
    "all_kernels = torch.cat(tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d27ad45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 2 # pca to 2d \n",
    "means = all_kernels.mean(axis=0).unsqueeze(0)\n",
    "centered_kernels = all_kernels - means\n",
    "cov_matrix = torch.matmul(centered_kernels.cuda().T, centered_kernels.cuda()) # need cuda otherwise takes forever\n",
    "v, w = torch.eig(cov_matrix, eigenvectors=True) # same comment as above\n",
    "pca_reduced_points = torch.matmul(centered_kernels.detach(), w[:, :n_features].cpu()) # dont need gpu here, though\n",
    "kernel_basis_vectors = w.view(9, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aab3e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the only thing this tells us is that our pca is very numerically unstable lol\n",
    "plt.bar(torch.arange(v.size(0)), v[:, 0].cpu()) # get real part of eigenvalues\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6285a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_experiment(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, basis_vectors, device): # need device in __init__ because of weight assignment - https://discuss.pytorch.org/t/typeerror-cannot-assign-torch-cuda-floattensor-as-parameter-weight-torch-nn-parameter-or-none-expected/61765\n",
    "        super().__init__()\n",
    "        \n",
    "        # conv basis weights\n",
    "        self.cbw1 = torch.nn.parameter.Parameter(torch.rand(16, 3, 9, device=device))\n",
    "        self.cbw2 = torch.nn.parameter.Parameter(torch.rand(16, 16, 9, device=device))\n",
    "        self.cbw3 = torch.nn.parameter.Parameter(torch.rand(16, 16, 9, device=device))\n",
    "        self.cbw4 = torch.nn.parameter.Parameter(torch.rand(10, 16, 9, device=device))\n",
    "        \n",
    "        self.linear = torch.nn.Linear(24*24, 1)\n",
    "        \n",
    "        # kernel basis vectors\n",
    "        self.kbf = basis_vectors.to(device)\n",
    "    def forward(self, x):\n",
    "        # should be able to optimize parameters? \n",
    "        conv1_weight = torch.einsum('bld,dnm -> blnm', self.cbw1, self.kbf)\n",
    "        x = torch.nn.functional.conv2d(input=x, weight=conv1_weight, stride=1)\n",
    "        x = torch.relu(x)\n",
    "        conv2_weight = torch.einsum('bld,dnm -> blnm', self.cbw2, self.kbf)\n",
    "        x = torch.nn.functional.conv2d(input=x, weight=conv2_weight, stride=1)\n",
    "        x = torch.relu(x)\n",
    "        conv3_weight = torch.einsum('bld,dnm -> blnm', self.cbw3, self.kbf)\n",
    "        x = torch.nn.functional.conv2d(input=x, weight=conv3_weight, stride=1)\n",
    "        x = torch.relu(x)\n",
    "        conv4_weight = torch.einsum('bld,dnm -> blnm', self.cbw4, self.kbf)\n",
    "        x = torch.nn.functional.conv2d(input=x, weight=conv4_weight, stride=1)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear(x.view(x.size(0), 10, -1))\n",
    "        return x.squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fe0f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_control(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cbw1 = torch.nn.Conv2d(3, 16, 3)\n",
    "        self.cbw2 = torch.nn.Conv2d(16, 16, 3)\n",
    "        self.cbw3 = torch.nn.Conv2d(16, 16, 3)\n",
    "        self.cbw4 = torch.nn.Conv2d(16, 10, 3)\n",
    "        \n",
    "        self.linear = torch.nn.Linear(24*24, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cbw1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.cbw2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.cbw3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.cbw4(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear(x.view(x.size(0), 10, -1))\n",
    "        return x.squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b180ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:2'\n",
    "model_control = Model_control().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfd05d4",
   "metadata": {},
   "source": [
    "### Train some stuff, see if it actually works (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4e66b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    acc = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = torch.nn.functional.cross_entropy(output, target)\n",
    "        out_softmax = torch.nn.functional.softmax(output, dim=-1)\n",
    "        _, idx = torch.max(out_softmax, -1)\n",
    "        acc += (idx == target).float().mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (1+batch_idx) % 150 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy:'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()),\n",
    "                 acc.item()/150)\n",
    "            acc_copy = acc.clone()\n",
    "            acc *= 0\n",
    "            yield acc_copy.item() / 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75f504dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data2/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3e40db2b7d4878a790a883673149bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data2/cifar-10-python.tar.gz to data2\n"
     ]
    }
   ],
   "source": [
    "transform=torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "trainset = torchvision.datasets.CIFAR10(root='data2', train=True, download=True, transform=transform)\n",
    "# trainset = torchvision.datasets.MNIST('data', train=False,transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=32)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ba9ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_control.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "29983456",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [4768/50000 (10%)]\tLoss: 1.010902\tAccuracy: 0.645625\n",
      "Train Epoch: 1 [9568/50000 (19%)]\tLoss: 0.819527\tAccuracy: 0.6183333333333333\n",
      "Train Epoch: 1 [14368/50000 (29%)]\tLoss: 1.048664\tAccuracy: 0.6204166666666666\n",
      "Train Epoch: 1 [19168/50000 (38%)]\tLoss: 1.100863\tAccuracy: 0.6235416666666667\n",
      "Train Epoch: 1 [23968/50000 (48%)]\tLoss: 1.003893\tAccuracy: 0.6195833333333334\n",
      "Train Epoch: 1 [28768/50000 (58%)]\tLoss: 1.010216\tAccuracy: 0.635\n",
      "Train Epoch: 1 [33568/50000 (67%)]\tLoss: 1.030761\tAccuracy: 0.6229166666666667\n",
      "Train Epoch: 1 [38368/50000 (77%)]\tLoss: 1.057224\tAccuracy: 0.6122916666666667\n",
      "Train Epoch: 1 [43168/50000 (86%)]\tLoss: 1.231648\tAccuracy: 0.618125\n",
      "Train Epoch: 1 [47968/50000 (96%)]\tLoss: 1.017509\tAccuracy: 0.6235416666666667\n",
      "Train Epoch: 2 [4768/50000 (10%)]\tLoss: 0.999099\tAccuracy: 0.645625\n",
      "Train Epoch: 2 [9568/50000 (19%)]\tLoss: 0.817919\tAccuracy: 0.62125\n",
      "Train Epoch: 2 [14368/50000 (29%)]\tLoss: 1.045815\tAccuracy: 0.62125\n",
      "Train Epoch: 2 [19168/50000 (38%)]\tLoss: 1.088906\tAccuracy: 0.6216666666666667\n",
      "Train Epoch: 2 [23968/50000 (48%)]\tLoss: 0.995685\tAccuracy: 0.6204166666666666\n",
      "Train Epoch: 2 [28768/50000 (58%)]\tLoss: 1.011182\tAccuracy: 0.6339583333333333\n",
      "Train Epoch: 2 [33568/50000 (67%)]\tLoss: 1.023659\tAccuracy: 0.6260416666666667\n",
      "Train Epoch: 2 [38368/50000 (77%)]\tLoss: 1.046986\tAccuracy: 0.6133333333333333\n",
      "Train Epoch: 2 [43168/50000 (86%)]\tLoss: 1.223208\tAccuracy: 0.620625\n",
      "Train Epoch: 2 [47968/50000 (96%)]\tLoss: 1.014960\tAccuracy: 0.62625\n",
      "Train Epoch: 3 [4768/50000 (10%)]\tLoss: 0.987688\tAccuracy: 0.6479166666666667\n",
      "Train Epoch: 3 [9568/50000 (19%)]\tLoss: 0.813277\tAccuracy: 0.6220833333333333\n",
      "Train Epoch: 3 [14368/50000 (29%)]\tLoss: 1.040948\tAccuracy: 0.624375\n",
      "Train Epoch: 3 [19168/50000 (38%)]\tLoss: 1.082013\tAccuracy: 0.6222916666666667\n",
      "Train Epoch: 3 [23968/50000 (48%)]\tLoss: 0.990270\tAccuracy: 0.6227083333333333\n",
      "Train Epoch: 3 [28768/50000 (58%)]\tLoss: 1.014431\tAccuracy: 0.636875\n",
      "Train Epoch: 3 [33568/50000 (67%)]\tLoss: 1.014639\tAccuracy: 0.6291666666666667\n",
      "Train Epoch: 3 [38368/50000 (77%)]\tLoss: 1.036111\tAccuracy: 0.6189583333333334\n",
      "Train Epoch: 3 [43168/50000 (86%)]\tLoss: 1.211899\tAccuracy: 0.6216666666666667\n",
      "Train Epoch: 3 [47968/50000 (96%)]\tLoss: 1.008953\tAccuracy: 0.626875\n",
      "Train Epoch: 4 [4768/50000 (10%)]\tLoss: 0.979254\tAccuracy: 0.65\n",
      "Train Epoch: 4 [9568/50000 (19%)]\tLoss: 0.807814\tAccuracy: 0.6235416666666667\n",
      "Train Epoch: 4 [14368/50000 (29%)]\tLoss: 1.037752\tAccuracy: 0.6283333333333333\n",
      "Train Epoch: 4 [19168/50000 (38%)]\tLoss: 1.073113\tAccuracy: 0.6264583333333333\n",
      "Train Epoch: 4 [23968/50000 (48%)]\tLoss: 0.980562\tAccuracy: 0.6247916666666666\n",
      "Train Epoch: 4 [28768/50000 (58%)]\tLoss: 1.017080\tAccuracy: 0.6379166666666667\n",
      "Train Epoch: 4 [33568/50000 (67%)]\tLoss: 1.008832\tAccuracy: 0.63125\n",
      "Train Epoch: 4 [38368/50000 (77%)]\tLoss: 1.028476\tAccuracy: 0.6252083333333334\n",
      "Train Epoch: 4 [43168/50000 (86%)]\tLoss: 1.202524\tAccuracy: 0.626875\n",
      "Train Epoch: 4 [47968/50000 (96%)]\tLoss: 1.005899\tAccuracy: 0.6304166666666666\n",
      "Train Epoch: 5 [4768/50000 (10%)]\tLoss: 0.965585\tAccuracy: 0.6508333333333334\n",
      "Train Epoch: 5 [9568/50000 (19%)]\tLoss: 0.802180\tAccuracy: 0.6239583333333333\n",
      "Train Epoch: 5 [14368/50000 (29%)]\tLoss: 1.029755\tAccuracy: 0.6297916666666666\n",
      "Train Epoch: 5 [19168/50000 (38%)]\tLoss: 1.062140\tAccuracy: 0.6291666666666667\n",
      "Train Epoch: 5 [23968/50000 (48%)]\tLoss: 0.975987\tAccuracy: 0.6289583333333333\n",
      "Train Epoch: 5 [28768/50000 (58%)]\tLoss: 1.019192\tAccuracy: 0.64\n",
      "Train Epoch: 5 [33568/50000 (67%)]\tLoss: 1.000351\tAccuracy: 0.63375\n",
      "Train Epoch: 5 [38368/50000 (77%)]\tLoss: 1.018671\tAccuracy: 0.6285416666666667\n",
      "Train Epoch: 5 [43168/50000 (86%)]\tLoss: 1.186090\tAccuracy: 0.6304166666666666\n",
      "Train Epoch: 5 [47968/50000 (96%)]\tLoss: 0.999705\tAccuracy: 0.6295833333333334\n",
      "Train Epoch: 6 [4768/50000 (10%)]\tLoss: 0.954211\tAccuracy: 0.6514583333333334\n",
      "Train Epoch: 6 [9568/50000 (19%)]\tLoss: 0.803430\tAccuracy: 0.6258333333333334\n",
      "Train Epoch: 6 [14368/50000 (29%)]\tLoss: 1.023463\tAccuracy: 0.6310416666666666\n",
      "Train Epoch: 6 [19168/50000 (38%)]\tLoss: 1.052520\tAccuracy: 0.629375\n",
      "Train Epoch: 6 [23968/50000 (48%)]\tLoss: 0.972210\tAccuracy: 0.630625\n",
      "Train Epoch: 6 [28768/50000 (58%)]\tLoss: 1.018500\tAccuracy: 0.6402083333333334\n",
      "Train Epoch: 6 [33568/50000 (67%)]\tLoss: 0.996189\tAccuracy: 0.6360416666666666\n",
      "Train Epoch: 6 [38368/50000 (77%)]\tLoss: 1.011063\tAccuracy: 0.6310416666666666\n",
      "Train Epoch: 6 [43168/50000 (86%)]\tLoss: 1.177254\tAccuracy: 0.6335416666666667\n",
      "Train Epoch: 6 [47968/50000 (96%)]\tLoss: 0.994126\tAccuracy: 0.6320833333333333\n",
      "Train Epoch: 7 [4768/50000 (10%)]\tLoss: 0.945683\tAccuracy: 0.6527083333333333\n",
      "Train Epoch: 7 [9568/50000 (19%)]\tLoss: 0.794060\tAccuracy: 0.6264583333333333\n",
      "Train Epoch: 7 [14368/50000 (29%)]\tLoss: 1.020525\tAccuracy: 0.6320833333333333\n",
      "Train Epoch: 7 [19168/50000 (38%)]\tLoss: 1.046691\tAccuracy: 0.6310416666666666\n",
      "Train Epoch: 7 [23968/50000 (48%)]\tLoss: 0.965165\tAccuracy: 0.6320833333333333\n",
      "Train Epoch: 7 [28768/50000 (58%)]\tLoss: 1.021454\tAccuracy: 0.6435416666666667\n",
      "Train Epoch: 7 [33568/50000 (67%)]\tLoss: 0.996541\tAccuracy: 0.6360416666666666\n",
      "Train Epoch: 7 [38368/50000 (77%)]\tLoss: 1.000389\tAccuracy: 0.633125\n",
      "Train Epoch: 7 [43168/50000 (86%)]\tLoss: 1.163790\tAccuracy: 0.6335416666666667\n",
      "Train Epoch: 7 [47968/50000 (96%)]\tLoss: 0.994229\tAccuracy: 0.6304166666666666\n",
      "Train Epoch: 8 [4768/50000 (10%)]\tLoss: 0.936395\tAccuracy: 0.6535416666666667\n",
      "Train Epoch: 8 [9568/50000 (19%)]\tLoss: 0.791726\tAccuracy: 0.6258333333333334\n",
      "Train Epoch: 8 [14368/50000 (29%)]\tLoss: 1.010074\tAccuracy: 0.6333333333333333\n",
      "Train Epoch: 8 [19168/50000 (38%)]\tLoss: 1.034510\tAccuracy: 0.6335416666666667\n",
      "Train Epoch: 8 [23968/50000 (48%)]\tLoss: 0.960314\tAccuracy: 0.6372916666666667\n",
      "Train Epoch: 8 [28768/50000 (58%)]\tLoss: 1.019801\tAccuracy: 0.64375\n",
      "Train Epoch: 8 [33568/50000 (67%)]\tLoss: 0.992840\tAccuracy: 0.640625\n",
      "Train Epoch: 8 [38368/50000 (77%)]\tLoss: 0.993535\tAccuracy: 0.6345833333333334\n",
      "Train Epoch: 8 [43168/50000 (86%)]\tLoss: 1.148173\tAccuracy: 0.635625\n",
      "Train Epoch: 8 [47968/50000 (96%)]\tLoss: 0.992992\tAccuracy: 0.633125\n",
      "Train Epoch: 9 [4768/50000 (10%)]\tLoss: 0.923510\tAccuracy: 0.655\n",
      "Train Epoch: 9 [9568/50000 (19%)]\tLoss: 0.782472\tAccuracy: 0.6289583333333333\n",
      "Train Epoch: 9 [14368/50000 (29%)]\tLoss: 1.003532\tAccuracy: 0.6345833333333334\n",
      "Train Epoch: 9 [19168/50000 (38%)]\tLoss: 1.029197\tAccuracy: 0.6329166666666667\n",
      "Train Epoch: 9 [23968/50000 (48%)]\tLoss: 0.959362\tAccuracy: 0.6429166666666667\n",
      "Train Epoch: 9 [28768/50000 (58%)]\tLoss: 1.020790\tAccuracy: 0.645625\n",
      "Train Epoch: 9 [33568/50000 (67%)]\tLoss: 0.988760\tAccuracy: 0.6433333333333333\n",
      "Train Epoch: 9 [38368/50000 (77%)]\tLoss: 0.989104\tAccuracy: 0.6335416666666667\n",
      "Train Epoch: 9 [43168/50000 (86%)]\tLoss: 1.136256\tAccuracy: 0.6385416666666667\n",
      "Train Epoch: 9 [47968/50000 (96%)]\tLoss: 0.997741\tAccuracy: 0.6360416666666666\n",
      "Train Epoch: 10 [4768/50000 (10%)]\tLoss: 0.913424\tAccuracy: 0.6572916666666667\n",
      "Train Epoch: 10 [9568/50000 (19%)]\tLoss: 0.773046\tAccuracy: 0.6297916666666666\n",
      "Train Epoch: 10 [14368/50000 (29%)]\tLoss: 0.990970\tAccuracy: 0.6335416666666667\n",
      "Train Epoch: 10 [19168/50000 (38%)]\tLoss: 1.023429\tAccuracy: 0.635\n",
      "Train Epoch: 10 [23968/50000 (48%)]\tLoss: 0.952754\tAccuracy: 0.6416666666666667\n",
      "Train Epoch: 10 [28768/50000 (58%)]\tLoss: 1.018724\tAccuracy: 0.6475\n",
      "Train Epoch: 10 [33568/50000 (67%)]\tLoss: 0.980958\tAccuracy: 0.6427083333333333\n",
      "Train Epoch: 10 [38368/50000 (77%)]\tLoss: 0.982026\tAccuracy: 0.6364583333333333\n",
      "Train Epoch: 10 [43168/50000 (86%)]\tLoss: 1.121596\tAccuracy: 0.6383333333333333\n",
      "Train Epoch: 10 [47968/50000 (96%)]\tLoss: 0.998190\tAccuracy: 0.6364583333333333\n",
      "Train Epoch: 11 [4768/50000 (10%)]\tLoss: 0.904588\tAccuracy: 0.6595833333333333\n",
      "Train Epoch: 11 [9568/50000 (19%)]\tLoss: 0.768133\tAccuracy: 0.6329166666666667\n",
      "Train Epoch: 11 [14368/50000 (29%)]\tLoss: 0.982148\tAccuracy: 0.6364583333333333\n",
      "Train Epoch: 11 [19168/50000 (38%)]\tLoss: 1.019771\tAccuracy: 0.635\n",
      "Train Epoch: 11 [23968/50000 (48%)]\tLoss: 0.950156\tAccuracy: 0.6420833333333333\n",
      "Train Epoch: 11 [28768/50000 (58%)]\tLoss: 1.019193\tAccuracy: 0.6483333333333333\n",
      "Train Epoch: 11 [33568/50000 (67%)]\tLoss: 0.981955\tAccuracy: 0.6458333333333334\n",
      "Train Epoch: 11 [38368/50000 (77%)]\tLoss: 0.974871\tAccuracy: 0.63875\n",
      "Train Epoch: 11 [43168/50000 (86%)]\tLoss: 1.110443\tAccuracy: 0.6404166666666666\n",
      "Train Epoch: 11 [47968/50000 (96%)]\tLoss: 0.997935\tAccuracy: 0.6395833333333333\n",
      "Train Epoch: 12 [4768/50000 (10%)]\tLoss: 0.897757\tAccuracy: 0.6629166666666667\n",
      "Train Epoch: 12 [9568/50000 (19%)]\tLoss: 0.758363\tAccuracy: 0.6327083333333333\n",
      "Train Epoch: 12 [14368/50000 (29%)]\tLoss: 0.977625\tAccuracy: 0.638125\n",
      "Train Epoch: 12 [19168/50000 (38%)]\tLoss: 1.013576\tAccuracy: 0.6370833333333333\n",
      "Train Epoch: 12 [23968/50000 (48%)]\tLoss: 0.944099\tAccuracy: 0.6433333333333333\n",
      "Train Epoch: 12 [28768/50000 (58%)]\tLoss: 1.015970\tAccuracy: 0.64875\n",
      "Train Epoch: 12 [33568/50000 (67%)]\tLoss: 0.975619\tAccuracy: 0.64625\n",
      "Train Epoch: 12 [38368/50000 (77%)]\tLoss: 0.962654\tAccuracy: 0.63875\n",
      "Train Epoch: 12 [43168/50000 (86%)]\tLoss: 1.103129\tAccuracy: 0.64\n",
      "Train Epoch: 12 [47968/50000 (96%)]\tLoss: 0.997228\tAccuracy: 0.64125\n",
      "Train Epoch: 13 [4768/50000 (10%)]\tLoss: 0.892444\tAccuracy: 0.6635416666666667\n",
      "Train Epoch: 13 [9568/50000 (19%)]\tLoss: 0.754468\tAccuracy: 0.6333333333333333\n",
      "Train Epoch: 13 [14368/50000 (29%)]\tLoss: 0.967808\tAccuracy: 0.63875\n",
      "Train Epoch: 13 [19168/50000 (38%)]\tLoss: 1.011425\tAccuracy: 0.6377083333333333\n",
      "Train Epoch: 13 [23968/50000 (48%)]\tLoss: 0.949009\tAccuracy: 0.643125\n",
      "Train Epoch: 13 [28768/50000 (58%)]\tLoss: 1.015488\tAccuracy: 0.65\n",
      "Train Epoch: 13 [33568/50000 (67%)]\tLoss: 0.974243\tAccuracy: 0.6483333333333333\n",
      "Train Epoch: 13 [38368/50000 (77%)]\tLoss: 0.955114\tAccuracy: 0.6391666666666667\n",
      "Train Epoch: 13 [43168/50000 (86%)]\tLoss: 1.096836\tAccuracy: 0.6445833333333333\n",
      "Train Epoch: 13 [47968/50000 (96%)]\tLoss: 0.996860\tAccuracy: 0.640625\n",
      "Train Epoch: 14 [4768/50000 (10%)]\tLoss: 0.885368\tAccuracy: 0.6633333333333333\n",
      "Train Epoch: 14 [9568/50000 (19%)]\tLoss: 0.748379\tAccuracy: 0.6352083333333334\n",
      "Train Epoch: 14 [14368/50000 (29%)]\tLoss: 0.959676\tAccuracy: 0.6420833333333333\n",
      "Train Epoch: 14 [19168/50000 (38%)]\tLoss: 1.010194\tAccuracy: 0.6397916666666666\n",
      "Train Epoch: 14 [23968/50000 (48%)]\tLoss: 0.947538\tAccuracy: 0.6439583333333333\n",
      "Train Epoch: 14 [28768/50000 (58%)]\tLoss: 1.015244\tAccuracy: 0.651875\n",
      "Train Epoch: 14 [33568/50000 (67%)]\tLoss: 0.969252\tAccuracy: 0.6489583333333333\n",
      "Train Epoch: 14 [38368/50000 (77%)]\tLoss: 0.946712\tAccuracy: 0.639375\n",
      "Train Epoch: 14 [43168/50000 (86%)]\tLoss: 1.086232\tAccuracy: 0.6445833333333333\n",
      "Train Epoch: 14 [47968/50000 (96%)]\tLoss: 1.002035\tAccuracy: 0.6420833333333333\n",
      "Train Epoch: 15 [4768/50000 (10%)]\tLoss: 0.878952\tAccuracy: 0.66375\n",
      "Train Epoch: 15 [9568/50000 (19%)]\tLoss: 0.748807\tAccuracy: 0.6379166666666667\n",
      "Train Epoch: 15 [14368/50000 (29%)]\tLoss: 0.954412\tAccuracy: 0.6441666666666667\n",
      "Train Epoch: 15 [19168/50000 (38%)]\tLoss: 1.008007\tAccuracy: 0.6410416666666666\n",
      "Train Epoch: 15 [23968/50000 (48%)]\tLoss: 0.943540\tAccuracy: 0.6479166666666667\n",
      "Train Epoch: 15 [28768/50000 (58%)]\tLoss: 1.011487\tAccuracy: 0.6535416666666667\n",
      "Train Epoch: 15 [33568/50000 (67%)]\tLoss: 0.966325\tAccuracy: 0.6508333333333334\n",
      "Train Epoch: 15 [38368/50000 (77%)]\tLoss: 0.942413\tAccuracy: 0.6410416666666666\n",
      "Train Epoch: 15 [43168/50000 (86%)]\tLoss: 1.080599\tAccuracy: 0.6477083333333333\n",
      "Train Epoch: 15 [47968/50000 (96%)]\tLoss: 1.002137\tAccuracy: 0.6460416666666666\n",
      "Train Epoch: 16 [4768/50000 (10%)]\tLoss: 0.869177\tAccuracy: 0.665\n",
      "Train Epoch: 16 [9568/50000 (19%)]\tLoss: 0.748373\tAccuracy: 0.6395833333333333\n",
      "Train Epoch: 16 [14368/50000 (29%)]\tLoss: 0.948335\tAccuracy: 0.6433333333333333\n",
      "Train Epoch: 16 [19168/50000 (38%)]\tLoss: 1.005594\tAccuracy: 0.6420833333333333\n",
      "Train Epoch: 16 [23968/50000 (48%)]\tLoss: 0.943904\tAccuracy: 0.6485416666666667\n",
      "Train Epoch: 16 [28768/50000 (58%)]\tLoss: 1.010661\tAccuracy: 0.655625\n",
      "Train Epoch: 16 [33568/50000 (67%)]\tLoss: 0.964355\tAccuracy: 0.653125\n",
      "Train Epoch: 16 [38368/50000 (77%)]\tLoss: 0.937017\tAccuracy: 0.6420833333333333\n",
      "Train Epoch: 16 [43168/50000 (86%)]\tLoss: 1.076713\tAccuracy: 0.650625\n",
      "Train Epoch: 16 [47968/50000 (96%)]\tLoss: 1.002778\tAccuracy: 0.6445833333333333\n",
      "Train Epoch: 17 [4768/50000 (10%)]\tLoss: 0.862657\tAccuracy: 0.665625\n",
      "Train Epoch: 17 [9568/50000 (19%)]\tLoss: 0.736504\tAccuracy: 0.6402083333333334\n",
      "Train Epoch: 17 [14368/50000 (29%)]\tLoss: 0.938740\tAccuracy: 0.6439583333333333\n",
      "Train Epoch: 17 [19168/50000 (38%)]\tLoss: 1.001435\tAccuracy: 0.6422916666666667\n",
      "Train Epoch: 17 [23968/50000 (48%)]\tLoss: 0.942361\tAccuracy: 0.650625\n",
      "Train Epoch: 17 [28768/50000 (58%)]\tLoss: 1.010585\tAccuracy: 0.6570833333333334\n",
      "Train Epoch: 17 [33568/50000 (67%)]\tLoss: 0.956899\tAccuracy: 0.65625\n",
      "Train Epoch: 17 [38368/50000 (77%)]\tLoss: 0.931077\tAccuracy: 0.643125\n",
      "Train Epoch: 17 [43168/50000 (86%)]\tLoss: 1.067429\tAccuracy: 0.6525\n",
      "Train Epoch: 17 [47968/50000 (96%)]\tLoss: 0.999826\tAccuracy: 0.645\n",
      "Train Epoch: 18 [4768/50000 (10%)]\tLoss: 0.855606\tAccuracy: 0.668125\n",
      "Train Epoch: 18 [9568/50000 (19%)]\tLoss: 0.732381\tAccuracy: 0.6441666666666667\n",
      "Train Epoch: 18 [14368/50000 (29%)]\tLoss: 0.933280\tAccuracy: 0.6470833333333333\n",
      "Train Epoch: 18 [19168/50000 (38%)]\tLoss: 0.998206\tAccuracy: 0.6439583333333333\n",
      "Train Epoch: 18 [23968/50000 (48%)]\tLoss: 0.940789\tAccuracy: 0.6516666666666666\n",
      "Train Epoch: 18 [28768/50000 (58%)]\tLoss: 1.011693\tAccuracy: 0.6570833333333334\n",
      "Train Epoch: 18 [33568/50000 (67%)]\tLoss: 0.953372\tAccuracy: 0.6577083333333333\n",
      "Train Epoch: 18 [38368/50000 (77%)]\tLoss: 0.918742\tAccuracy: 0.6447916666666667\n",
      "Train Epoch: 18 [43168/50000 (86%)]\tLoss: 1.062052\tAccuracy: 0.654375\n",
      "Train Epoch: 18 [47968/50000 (96%)]\tLoss: 0.998841\tAccuracy: 0.6460416666666666\n",
      "Train Epoch: 19 [4768/50000 (10%)]\tLoss: 0.848149\tAccuracy: 0.67\n",
      "Train Epoch: 19 [9568/50000 (19%)]\tLoss: 0.728766\tAccuracy: 0.6454166666666666\n",
      "Train Epoch: 19 [14368/50000 (29%)]\tLoss: 0.922306\tAccuracy: 0.6483333333333333\n",
      "Train Epoch: 19 [19168/50000 (38%)]\tLoss: 0.999055\tAccuracy: 0.6447916666666667\n",
      "Train Epoch: 19 [23968/50000 (48%)]\tLoss: 0.936823\tAccuracy: 0.6539583333333333\n",
      "Train Epoch: 19 [28768/50000 (58%)]\tLoss: 1.009532\tAccuracy: 0.65875\n",
      "Train Epoch: 19 [33568/50000 (67%)]\tLoss: 0.952210\tAccuracy: 0.6572916666666667\n",
      "Train Epoch: 19 [38368/50000 (77%)]\tLoss: 0.906346\tAccuracy: 0.645625\n",
      "Train Epoch: 19 [43168/50000 (86%)]\tLoss: 1.050156\tAccuracy: 0.6570833333333334\n",
      "Train Epoch: 19 [47968/50000 (96%)]\tLoss: 0.995495\tAccuracy: 0.6466666666666666\n",
      "Train Epoch: 20 [4768/50000 (10%)]\tLoss: 0.838148\tAccuracy: 0.6733333333333333\n",
      "Train Epoch: 20 [9568/50000 (19%)]\tLoss: 0.722431\tAccuracy: 0.6477083333333333\n",
      "Train Epoch: 20 [14368/50000 (29%)]\tLoss: 0.913963\tAccuracy: 0.6491666666666667\n",
      "Train Epoch: 20 [19168/50000 (38%)]\tLoss: 0.990735\tAccuracy: 0.6477083333333333\n",
      "Train Epoch: 20 [23968/50000 (48%)]\tLoss: 0.931136\tAccuracy: 0.6545833333333333\n",
      "Train Epoch: 20 [28768/50000 (58%)]\tLoss: 1.004642\tAccuracy: 0.659375\n",
      "Train Epoch: 20 [33568/50000 (67%)]\tLoss: 0.947628\tAccuracy: 0.6589583333333333\n",
      "Train Epoch: 20 [38368/50000 (77%)]\tLoss: 0.899913\tAccuracy: 0.6485416666666667\n",
      "Train Epoch: 20 [43168/50000 (86%)]\tLoss: 1.047003\tAccuracy: 0.6597916666666667\n",
      "Train Epoch: 20 [47968/50000 (96%)]\tLoss: 0.988237\tAccuracy: 0.6466666666666666\n",
      "Train Epoch: 21 [4768/50000 (10%)]\tLoss: 0.831034\tAccuracy: 0.6745833333333333\n",
      "Train Epoch: 21 [9568/50000 (19%)]\tLoss: 0.720779\tAccuracy: 0.648125\n",
      "Train Epoch: 21 [14368/50000 (29%)]\tLoss: 0.907601\tAccuracy: 0.65\n",
      "Train Epoch: 21 [19168/50000 (38%)]\tLoss: 0.985981\tAccuracy: 0.6485416666666667\n",
      "Train Epoch: 21 [23968/50000 (48%)]\tLoss: 0.934121\tAccuracy: 0.655\n",
      "Train Epoch: 21 [28768/50000 (58%)]\tLoss: 0.998838\tAccuracy: 0.6608333333333334\n",
      "Train Epoch: 21 [33568/50000 (67%)]\tLoss: 0.947618\tAccuracy: 0.66\n",
      "Train Epoch: 21 [38368/50000 (77%)]\tLoss: 0.897381\tAccuracy: 0.6483333333333333\n",
      "Train Epoch: 21 [43168/50000 (86%)]\tLoss: 1.038858\tAccuracy: 0.66\n",
      "Train Epoch: 21 [47968/50000 (96%)]\tLoss: 0.983267\tAccuracy: 0.646875\n",
      "Train Epoch: 22 [4768/50000 (10%)]\tLoss: 0.826704\tAccuracy: 0.676875\n",
      "Train Epoch: 22 [9568/50000 (19%)]\tLoss: 0.720582\tAccuracy: 0.64875\n",
      "Train Epoch: 22 [14368/50000 (29%)]\tLoss: 0.899990\tAccuracy: 0.6502083333333334\n",
      "Train Epoch: 22 [19168/50000 (38%)]\tLoss: 0.979260\tAccuracy: 0.6497916666666667\n",
      "Train Epoch: 22 [23968/50000 (48%)]\tLoss: 0.935443\tAccuracy: 0.6566666666666666\n",
      "Train Epoch: 22 [28768/50000 (58%)]\tLoss: 0.992717\tAccuracy: 0.6614583333333334\n",
      "Train Epoch: 22 [33568/50000 (67%)]\tLoss: 0.944271\tAccuracy: 0.65875\n",
      "Train Epoch: 22 [38368/50000 (77%)]\tLoss: 0.891694\tAccuracy: 0.65\n",
      "Train Epoch: 22 [43168/50000 (86%)]\tLoss: 1.032034\tAccuracy: 0.6608333333333334\n",
      "Train Epoch: 22 [47968/50000 (96%)]\tLoss: 0.978098\tAccuracy: 0.6470833333333333\n",
      "Train Epoch: 23 [4768/50000 (10%)]\tLoss: 0.823711\tAccuracy: 0.6772916666666666\n",
      "Train Epoch: 23 [9568/50000 (19%)]\tLoss: 0.720521\tAccuracy: 0.6495833333333333\n",
      "Train Epoch: 23 [14368/50000 (29%)]\tLoss: 0.898455\tAccuracy: 0.6502083333333334\n",
      "Train Epoch: 23 [19168/50000 (38%)]\tLoss: 0.975272\tAccuracy: 0.6508333333333334\n",
      "Train Epoch: 23 [23968/50000 (48%)]\tLoss: 0.937704\tAccuracy: 0.6585416666666667\n",
      "Train Epoch: 23 [28768/50000 (58%)]\tLoss: 0.988612\tAccuracy: 0.6625\n",
      "Train Epoch: 23 [33568/50000 (67%)]\tLoss: 0.943442\tAccuracy: 0.6614583333333334\n",
      "Train Epoch: 23 [38368/50000 (77%)]\tLoss: 0.879902\tAccuracy: 0.6520833333333333\n",
      "Train Epoch: 23 [43168/50000 (86%)]\tLoss: 1.024578\tAccuracy: 0.6629166666666667\n",
      "Train Epoch: 23 [47968/50000 (96%)]\tLoss: 0.980335\tAccuracy: 0.6491666666666667\n",
      "Train Epoch: 24 [4768/50000 (10%)]\tLoss: 0.819280\tAccuracy: 0.6783333333333333\n",
      "Train Epoch: 24 [9568/50000 (19%)]\tLoss: 0.719747\tAccuracy: 0.650625\n",
      "Train Epoch: 24 [14368/50000 (29%)]\tLoss: 0.895633\tAccuracy: 0.6510416666666666\n",
      "Train Epoch: 24 [19168/50000 (38%)]\tLoss: 0.970197\tAccuracy: 0.6525\n",
      "Train Epoch: 24 [23968/50000 (48%)]\tLoss: 0.935390\tAccuracy: 0.6595833333333333\n",
      "Train Epoch: 24 [28768/50000 (58%)]\tLoss: 0.981990\tAccuracy: 0.6652083333333333\n",
      "Train Epoch: 24 [33568/50000 (67%)]\tLoss: 0.946570\tAccuracy: 0.66375\n",
      "Train Epoch: 24 [38368/50000 (77%)]\tLoss: 0.874991\tAccuracy: 0.65375\n",
      "Train Epoch: 24 [43168/50000 (86%)]\tLoss: 1.013166\tAccuracy: 0.663125\n",
      "Train Epoch: 24 [47968/50000 (96%)]\tLoss: 0.979711\tAccuracy: 0.6510416666666666\n",
      "Train Epoch: 25 [4768/50000 (10%)]\tLoss: 0.813718\tAccuracy: 0.680625\n",
      "Train Epoch: 25 [9568/50000 (19%)]\tLoss: 0.719428\tAccuracy: 0.6510416666666666\n",
      "Train Epoch: 25 [14368/50000 (29%)]\tLoss: 0.894964\tAccuracy: 0.654375\n",
      "Train Epoch: 25 [19168/50000 (38%)]\tLoss: 0.965901\tAccuracy: 0.6525\n",
      "Train Epoch: 25 [23968/50000 (48%)]\tLoss: 0.932389\tAccuracy: 0.6604166666666667\n",
      "Train Epoch: 25 [28768/50000 (58%)]\tLoss: 0.978250\tAccuracy: 0.6658333333333334\n",
      "Train Epoch: 25 [33568/50000 (67%)]\tLoss: 0.944666\tAccuracy: 0.664375\n",
      "Train Epoch: 25 [38368/50000 (77%)]\tLoss: 0.870768\tAccuracy: 0.6541666666666667\n",
      "Train Epoch: 25 [43168/50000 (86%)]\tLoss: 1.010123\tAccuracy: 0.6645833333333333\n",
      "Train Epoch: 25 [47968/50000 (96%)]\tLoss: 0.976711\tAccuracy: 0.6510416666666666\n",
      "Train Epoch: 26 [4768/50000 (10%)]\tLoss: 0.809168\tAccuracy: 0.6835416666666667\n",
      "Train Epoch: 26 [9568/50000 (19%)]\tLoss: 0.724374\tAccuracy: 0.6541666666666667\n",
      "Train Epoch: 26 [14368/50000 (29%)]\tLoss: 0.886895\tAccuracy: 0.6547916666666667\n",
      "Train Epoch: 26 [19168/50000 (38%)]\tLoss: 0.960423\tAccuracy: 0.6541666666666667\n",
      "Train Epoch: 26 [23968/50000 (48%)]\tLoss: 0.932601\tAccuracy: 0.6614583333333334\n",
      "Train Epoch: 26 [28768/50000 (58%)]\tLoss: 0.976540\tAccuracy: 0.666875\n",
      "Train Epoch: 26 [33568/50000 (67%)]\tLoss: 0.938127\tAccuracy: 0.6654166666666667\n",
      "Train Epoch: 26 [38368/50000 (77%)]\tLoss: 0.862005\tAccuracy: 0.6564583333333334\n",
      "Train Epoch: 26 [43168/50000 (86%)]\tLoss: 1.006248\tAccuracy: 0.6654166666666667\n",
      "Train Epoch: 26 [47968/50000 (96%)]\tLoss: 0.970615\tAccuracy: 0.65375\n",
      "Train Epoch: 27 [4768/50000 (10%)]\tLoss: 0.804636\tAccuracy: 0.6845833333333333\n",
      "Train Epoch: 27 [9568/50000 (19%)]\tLoss: 0.727759\tAccuracy: 0.6533333333333333\n",
      "Train Epoch: 27 [14368/50000 (29%)]\tLoss: 0.885435\tAccuracy: 0.6554166666666666\n",
      "Train Epoch: 27 [19168/50000 (38%)]\tLoss: 0.956737\tAccuracy: 0.6570833333333334\n",
      "Train Epoch: 27 [23968/50000 (48%)]\tLoss: 0.932434\tAccuracy: 0.6622916666666666\n",
      "Train Epoch: 27 [28768/50000 (58%)]\tLoss: 0.974078\tAccuracy: 0.6666666666666666\n",
      "Train Epoch: 27 [33568/50000 (67%)]\tLoss: 0.938319\tAccuracy: 0.6677083333333333\n",
      "Train Epoch: 27 [38368/50000 (77%)]\tLoss: 0.858337\tAccuracy: 0.6570833333333334\n",
      "Train Epoch: 27 [43168/50000 (86%)]\tLoss: 1.003735\tAccuracy: 0.6652083333333333\n",
      "Train Epoch: 27 [47968/50000 (96%)]\tLoss: 0.971514\tAccuracy: 0.653125\n",
      "Train Epoch: 28 [4768/50000 (10%)]\tLoss: 0.799864\tAccuracy: 0.685625\n",
      "Train Epoch: 28 [9568/50000 (19%)]\tLoss: 0.734528\tAccuracy: 0.653125\n",
      "Train Epoch: 28 [14368/50000 (29%)]\tLoss: 0.882496\tAccuracy: 0.6558333333333334\n",
      "Train Epoch: 28 [19168/50000 (38%)]\tLoss: 0.950988\tAccuracy: 0.6589583333333333\n",
      "Train Epoch: 28 [23968/50000 (48%)]\tLoss: 0.932888\tAccuracy: 0.66375\n",
      "Train Epoch: 28 [28768/50000 (58%)]\tLoss: 0.970389\tAccuracy: 0.6679166666666667\n",
      "Train Epoch: 28 [33568/50000 (67%)]\tLoss: 0.939714\tAccuracy: 0.66875\n",
      "Train Epoch: 28 [38368/50000 (77%)]\tLoss: 0.850989\tAccuracy: 0.6602083333333333\n",
      "Train Epoch: 28 [43168/50000 (86%)]\tLoss: 1.000668\tAccuracy: 0.6677083333333333\n",
      "Train Epoch: 28 [47968/50000 (96%)]\tLoss: 0.971546\tAccuracy: 0.6566666666666666\n",
      "Train Epoch: 29 [4768/50000 (10%)]\tLoss: 0.795248\tAccuracy: 0.68625\n",
      "Train Epoch: 29 [9568/50000 (19%)]\tLoss: 0.739488\tAccuracy: 0.655625\n",
      "Train Epoch: 29 [14368/50000 (29%)]\tLoss: 0.875904\tAccuracy: 0.6585416666666667\n",
      "Train Epoch: 29 [19168/50000 (38%)]\tLoss: 0.947817\tAccuracy: 0.659375\n",
      "Train Epoch: 29 [23968/50000 (48%)]\tLoss: 0.931473\tAccuracy: 0.66375\n",
      "Train Epoch: 29 [28768/50000 (58%)]\tLoss: 0.969180\tAccuracy: 0.6695833333333333\n",
      "Train Epoch: 29 [33568/50000 (67%)]\tLoss: 0.939707\tAccuracy: 0.6695833333333333\n",
      "Train Epoch: 29 [38368/50000 (77%)]\tLoss: 0.854633\tAccuracy: 0.661875\n",
      "Train Epoch: 29 [43168/50000 (86%)]\tLoss: 0.990428\tAccuracy: 0.669375\n",
      "Train Epoch: 29 [47968/50000 (96%)]\tLoss: 0.965592\tAccuracy: 0.6560416666666666\n"
     ]
    }
   ],
   "source": [
    "# control run\n",
    "# loss_control = []\n",
    "epochs = 30\n",
    "for epoch in range(1, epochs):\n",
    "    for loss_val in train(model_control, device, train_loader, optimizer, epoch):\n",
    "        loss_control.append(loss_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4a12e6b8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [4768/50000 (10%)]\tLoss: 2.327898\tAccuracy: 0.15791666666666668\n",
      "Train Epoch: 1 [9568/50000 (19%)]\tLoss: 2.123215\tAccuracy: 0.19895833333333332\n",
      "Train Epoch: 1 [14368/50000 (29%)]\tLoss: 2.119751\tAccuracy: 0.19395833333333334\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-2bb131e84e9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_control2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_control2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss_control2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-8091b908afe3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/will-gpu/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/will-gpu/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/will-gpu/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/will-gpu/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/will-gpu/lib/python3.8/site-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/will-gpu/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/will-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/will-gpu/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/will-gpu/lib/python3.8/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# control run\n",
    "# loss_control2 = []\n",
    "epochs = 30\n",
    "model_control2 = Model_control().to(device)\n",
    "optimizer2 = torch.optim.Adam(model_control2.parameters(), lr=3e-4)\n",
    "for epoch in range(1, epochs):\n",
    "    for loss_val in train(model_control2, device, train_loader, optimizer2, epoch):\n",
    "        loss_control2.append(loss_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9667f2bc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [4768/50000 (10%)]\tLoss: 1.560789\tAccuracy: 0.333125\n",
      "Train Epoch: 1 [9568/50000 (19%)]\tLoss: 1.648169\tAccuracy: 0.33875\n",
      "Train Epoch: 1 [14368/50000 (29%)]\tLoss: 1.560525\tAccuracy: 0.34770833333333334\n",
      "Train Epoch: 1 [19168/50000 (38%)]\tLoss: 1.701597\tAccuracy: 0.35479166666666667\n",
      "Train Epoch: 1 [23968/50000 (48%)]\tLoss: 1.778425\tAccuracy: 0.38604166666666667\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-b4fab7842787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# optimizer3 = torch.optim.Adam(model_control3.parameters(), lr=3e-4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_control3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss_control3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-8091b908afe3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# control run\n",
    "# loss_control3 = []\n",
    "epochs = 30\n",
    "# model_control3 = Model_control().to(device)\n",
    "# optimizer3 = torch.optim.Adam(model_control3.parameters(), lr=3e-4)\n",
    "for epoch in range(1, epochs):\n",
    "    for loss_val in train(model_control3, device, train_loader, optimizer3, epoch):\n",
    "        loss_control3.append(loss_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c0220b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = []\n",
    "for name, tensor in model_control.state_dict().items():\n",
    "    if ('weight' in name) & ('linear' not in name):\n",
    "        tensors.append(tensor.view(-1, 9)) # 9 because we are using 3x3 kernels \n",
    "# for name, tensor in model_control2.state_dict().items():\n",
    "#     if ('weight' in name) & ('linear' not in name):\n",
    "#         tensors.append(tensor.view(-1, 9)) # 9 because we are using 3x3 kernels \n",
    "# for name, tensor in model_control3.state_dict().items():\n",
    "#     if ('weight' in name) & ('linear' not in name):\n",
    "#         tensors.append(tensor.view(-1, 9)) # 9 because we are using 3x3 kernels \n",
    "all_kernels = torch.cat(tensors).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "56267793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([720, 9])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_kernels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "10558b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 2 # pca to 2d \n",
    "means = all_kernels.mean(axis=0).unsqueeze(0)\n",
    "centered_kernels = all_kernels - means\n",
    "cov_matrix = torch.matmul(centered_kernels.cuda().T, centered_kernels.cuda()) # need cuda otherwise takes forever\n",
    "v, w = torch.eig(cov_matrix, eigenvectors=True) # same comment as above\n",
    "pca_reduced_points = torch.matmul(centered_kernels.detach(), w[:, :n_features].cpu()) # dont need gpu here, though\n",
    "kernel_basis_vectors = w.view(9, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ff22d198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the only thing this tells us is that our pca is very numerically unstable lol\n",
    "plt.bar(torch.arange(v.size(0)), v[:, 0].cpu()) # get real part of eigenvalues\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7be288cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_experiment(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, basis_vectors, device): # need device in __init__ because of weight assignment - https://discuss.pytorch.org/t/typeerror-cannot-assign-torch-cuda-floattensor-as-parameter-weight-torch-nn-parameter-or-none-expected/61765\n",
    "        super().__init__()\n",
    "        \n",
    "        # conv basis weights\n",
    "        norm_divisor = 10\n",
    "        self.cbw1 = torch.nn.parameter.Parameter((torch.rand(16, 3, 4, device=device)-.5)/norm_divisor)\n",
    "        self.cbw2 = torch.nn.parameter.Parameter((torch.rand(16, 16, 4, device=device)-.5)/norm_divisor)\n",
    "        self.cbw3 = torch.nn.parameter.Parameter((torch.rand(16, 16, 4, device=device)-.5)/norm_divisor)\n",
    "        self.cbw4 = torch.nn.parameter.Parameter((torch.rand(10, 16, 4, device=device)-.5)/norm_divisor)\n",
    "        \n",
    "        self.linear = torch.nn.Linear(24*24, 1)\n",
    "        \n",
    "        # kernel basis vectors\n",
    "        self.kbf = basis_vectors.to(device)\n",
    "    def forward(self, x):\n",
    "        # should be able to optimize parameters? \n",
    "        conv1_weight = torch.einsum('bld,dnm -> blnm', self.cbw1, self.kbf)\n",
    "        x = torch.nn.functional.conv2d(input=x, weight=conv1_weight, stride=1)\n",
    "        \n",
    "        conv2_weight = torch.einsum('bld,dnm -> blnm', self.cbw2, self.kbf)\n",
    "        x = torch.nn.functional.conv2d(input=x, weight=conv2_weight, stride=1)\n",
    "        \n",
    "        conv3_weight = torch.einsum('bld,dnm -> blnm', self.cbw3, self.kbf)\n",
    "        x = torch.nn.functional.conv2d(input=x, weight=conv3_weight, stride=1)\n",
    "        \n",
    "        conv4_weight = torch.einsum('bld,dnm -> blnm', self.cbw4, self.kbf)\n",
    "        x = torch.nn.functional.conv2d(input=x, weight=conv4_weight, stride=1)\n",
    "        \n",
    "        x = self.linear(x.view(x.size(0), 10, -1))\n",
    "        return x.squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c5b5fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ex = Model_experiment(kernel_basis_vectors[:4], device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0bea1ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_ex = torch.optim.Adam(model_ex.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6a6d4b95",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [4768/50000 (10%)]\tLoss: 2.235107\tAccuracy: 0.10708333333333334\n",
      "Train Epoch: 1 [9568/50000 (19%)]\tLoss: 2.262482\tAccuracy: 0.178125\n",
      "Train Epoch: 1 [14368/50000 (29%)]\tLoss: 2.218242\tAccuracy: 0.19520833333333334\n",
      "Train Epoch: 1 [19168/50000 (38%)]\tLoss: 1.907750\tAccuracy: 0.20895833333333333\n",
      "Train Epoch: 1 [23968/50000 (48%)]\tLoss: 2.048964\tAccuracy: 0.23\n",
      "Train Epoch: 1 [28768/50000 (58%)]\tLoss: 2.299437\tAccuracy: 0.234375\n",
      "Train Epoch: 1 [33568/50000 (67%)]\tLoss: 2.073807\tAccuracy: 0.24270833333333333\n",
      "Train Epoch: 1 [38368/50000 (77%)]\tLoss: 2.100562\tAccuracy: 0.25875\n",
      "Train Epoch: 1 [43168/50000 (86%)]\tLoss: 2.297457\tAccuracy: 0.24770833333333334\n",
      "Train Epoch: 1 [47968/50000 (96%)]\tLoss: 1.913155\tAccuracy: 0.259375\n",
      "Train Epoch: 2 [4768/50000 (10%)]\tLoss: 2.015248\tAccuracy: 0.26708333333333334\n",
      "Train Epoch: 2 [9568/50000 (19%)]\tLoss: 2.018712\tAccuracy: 0.255625\n",
      "Train Epoch: 2 [14368/50000 (29%)]\tLoss: 2.094684\tAccuracy: 0.2679166666666667\n",
      "Train Epoch: 2 [19168/50000 (38%)]\tLoss: 1.851367\tAccuracy: 0.26208333333333333\n",
      "Train Epoch: 2 [23968/50000 (48%)]\tLoss: 1.965411\tAccuracy: 0.2764583333333333\n",
      "Train Epoch: 2 [28768/50000 (58%)]\tLoss: 2.199475\tAccuracy: 0.28770833333333334\n",
      "Train Epoch: 2 [33568/50000 (67%)]\tLoss: 2.027083\tAccuracy: 0.2875\n",
      "Train Epoch: 2 [38368/50000 (77%)]\tLoss: 2.019212\tAccuracy: 0.2808333333333333\n",
      "Train Epoch: 2 [43168/50000 (86%)]\tLoss: 2.265846\tAccuracy: 0.28229166666666666\n",
      "Train Epoch: 2 [47968/50000 (96%)]\tLoss: 1.878102\tAccuracy: 0.28270833333333334\n",
      "Train Epoch: 3 [4768/50000 (10%)]\tLoss: 1.977082\tAccuracy: 0.2991666666666667\n",
      "Train Epoch: 3 [9568/50000 (19%)]\tLoss: 1.966991\tAccuracy: 0.2889583333333333\n",
      "Train Epoch: 3 [14368/50000 (29%)]\tLoss: 2.016494\tAccuracy: 0.291875\n",
      "Train Epoch: 3 [19168/50000 (38%)]\tLoss: 1.818609\tAccuracy: 0.28375\n",
      "Train Epoch: 3 [23968/50000 (48%)]\tLoss: 1.895859\tAccuracy: 0.295625\n",
      "Train Epoch: 3 [28768/50000 (58%)]\tLoss: 2.155998\tAccuracy: 0.2972916666666667\n",
      "Train Epoch: 3 [33568/50000 (67%)]\tLoss: 1.968157\tAccuracy: 0.30354166666666665\n",
      "Train Epoch: 3 [38368/50000 (77%)]\tLoss: 1.987107\tAccuracy: 0.298125\n",
      "Train Epoch: 3 [43168/50000 (86%)]\tLoss: 2.226132\tAccuracy: 0.2991666666666667\n",
      "Train Epoch: 3 [47968/50000 (96%)]\tLoss: 1.824869\tAccuracy: 0.2975\n",
      "Train Epoch: 4 [4768/50000 (10%)]\tLoss: 1.911693\tAccuracy: 0.3122916666666667\n",
      "Train Epoch: 4 [9568/50000 (19%)]\tLoss: 1.928945\tAccuracy: 0.3075\n",
      "Train Epoch: 4 [14368/50000 (29%)]\tLoss: 1.941033\tAccuracy: 0.320625\n",
      "Train Epoch: 4 [19168/50000 (38%)]\tLoss: 1.747110\tAccuracy: 0.2991666666666667\n",
      "Train Epoch: 4 [23968/50000 (48%)]\tLoss: 1.859661\tAccuracy: 0.3177083333333333\n",
      "Train Epoch: 4 [28768/50000 (58%)]\tLoss: 2.125477\tAccuracy: 0.31375\n",
      "Train Epoch: 4 [33568/50000 (67%)]\tLoss: 1.920158\tAccuracy: 0.3225\n",
      "Train Epoch: 4 [38368/50000 (77%)]\tLoss: 1.957174\tAccuracy: 0.32208333333333333\n",
      "Train Epoch: 4 [43168/50000 (86%)]\tLoss: 2.146557\tAccuracy: 0.31333333333333335\n",
      "Train Epoch: 4 [47968/50000 (96%)]\tLoss: 1.769783\tAccuracy: 0.3152083333333333\n",
      "Train Epoch: 5 [4768/50000 (10%)]\tLoss: 1.863590\tAccuracy: 0.324375\n",
      "Train Epoch: 5 [9568/50000 (19%)]\tLoss: 1.898912\tAccuracy: 0.31916666666666665\n",
      "Train Epoch: 5 [14368/50000 (29%)]\tLoss: 1.885773\tAccuracy: 0.3283333333333333\n",
      "Train Epoch: 5 [19168/50000 (38%)]\tLoss: 1.710321\tAccuracy: 0.3175\n",
      "Train Epoch: 5 [23968/50000 (48%)]\tLoss: 1.850510\tAccuracy: 0.32208333333333333\n",
      "Train Epoch: 5 [28768/50000 (58%)]\tLoss: 2.098717\tAccuracy: 0.32145833333333335\n",
      "Train Epoch: 5 [33568/50000 (67%)]\tLoss: 1.946646\tAccuracy: 0.32729166666666665\n",
      "Train Epoch: 5 [38368/50000 (77%)]\tLoss: 1.936189\tAccuracy: 0.32645833333333335\n",
      "Train Epoch: 5 [43168/50000 (86%)]\tLoss: 2.091784\tAccuracy: 0.31875\n",
      "Train Epoch: 5 [47968/50000 (96%)]\tLoss: 1.745702\tAccuracy: 0.32208333333333333\n",
      "Train Epoch: 6 [4768/50000 (10%)]\tLoss: 1.827544\tAccuracy: 0.3333333333333333\n",
      "Train Epoch: 6 [9568/50000 (19%)]\tLoss: 1.882738\tAccuracy: 0.32375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-c80637899e1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mloss_ex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-8091b908afe3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mout_softmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/will-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-172-1e856ca9252f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv1_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mconv2_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bld,dnm -> blnm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkbf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv2_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/will-gpu/lib/python3.8/site-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_operands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# control run\n",
    "loss_ex = []\n",
    "epochs = 30\n",
    "for epoch in range(1, epochs):\n",
    "    for loss_val in train(model_ex, device, train_loader, optimizer_ex, epoch):\n",
    "        loss_ex.append(loss_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5a7513a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_ex, label='PCA thing')\n",
    "plt.plot(loss_control, label='control')\n",
    "plt.legend()\n",
    "plt.title('MNIST accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f396cb8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-will-gpu] *",
   "language": "python",
   "name": "conda-env-.conda-will-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
